{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:18:38.093830Z",
     "start_time": "2023-12-19T14:18:21.391991700Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import sinling\n",
    "\n",
    "# Load the XLSX file into a DataFrame\n",
    "xlsx_file = \"wsd_irst_attempt.xlsx\"\n",
    "df = pd.read_excel(xlsx_file)\n",
    "\n",
    "# # Convert the DataFrame to a CSV file\n",
    "# csv_file = \"wsd_irst_attempt.csv\"\n",
    "# df.to_csv(csv_file, index=False)  # Set index=False to exclude the DataFrame index in the CSV file\n",
    "#\n",
    "# print(f\"XLSX file '{xlsx_file}' has been successfully converted to CSV file '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching words and their counts:\n",
      "ගන්න: \t The Word Occurrence : 1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def search_csv(file_path, sentence):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)  # Assuming the first row is a header\n",
    "\n",
    "        # Assuming the sentence is in the first column (index 0)\n",
    "        sentence_column_index = 1\n",
    "\n",
    "        # Initialize a dictionary to store matching words and their counts\n",
    "        match_count_dict = {}\n",
    "\n",
    "        # Split the sentence into words\n",
    "        sentence_words = sentence.split()\n",
    "\n",
    "        for row in csv_reader:\n",
    "            # Get the word from the CSV column\n",
    "            csv_column_word = row[sentence_column_index]\n",
    "\n",
    "            # Check if the CSV column word is in the sentence\n",
    "            if csv_column_word in sentence_words:\n",
    "                # Update the match count in the dictionary\n",
    "                match_count_dict[csv_column_word] = match_count_dict.get(csv_column_word, 0) + 1\n",
    "\n",
    "        # Print the matching words and their counts\n",
    "        if match_count_dict:\n",
    "            print(\"Matching words and their counts:\")\n",
    "            for word, count in match_count_dict.items():\n",
    "                print(f\"{word}: \\t The Word Occurrence : {count}\")\n",
    "        else:\n",
    "            print(\"No matches found in the CSV file.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'wsd_irst_attempt.csv'\n",
    "search_sentence = 'ඔතන තියෙන දදය ගන්න පසුව පැමිණෙනවා'\n",
    "\n",
    "search_csv(csv_file_path, search_sentence)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:20:13.589042200Z",
     "start_time": "2023-12-19T14:20:13.456015700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sinling import SinhalaStemmer\n",
    "# Test Case 1\n",
    "\n",
    "from sinling import SinhalaTokenizer, POSTagger\n",
    "\n",
    "tokenizer = SinhalaTokenizer()\n",
    "\n",
    "document = 'අමර ඔතන දදයක් තබන්න ඉන්පසු ඔබ ගෙදරට යන්න'  # may contain multiple sentences\n",
    "\n",
    "tokenized_sentences = [tokenizer.tokenize(f'{ss}.') for ss in tokenizer.split_sentences(document)]\n",
    "\n",
    "tagger = POSTagger()\n",
    "\n",
    "pos_tags = tagger.predict(tokenized_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:20:23.277404600Z",
     "start_time": "2023-12-19T14:20:22.470197800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[[('අමර', 'NNC'),\n  ('ඔතන', 'VP'),\n  ('දදයක්', 'NNC'),\n  ('තබන්න', 'VNN'),\n  ('ඉන්පසු', 'POST'),\n  ('ඔබ', 'PRP'),\n  ('ගෙදරට', 'NNC'),\n  ('යන්න', 'POST'),\n  ('.', 'FS')]]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:20:24.630251400Z",
     "start_time": "2023-12-19T14:20:24.567751300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: NNC, Count: 3\n",
      "Tag: VP, Count: 1\n",
      "Tag: VNN, Count: 1\n",
      "Tag: POST, Count: 2\n",
      "Tag: PRP, Count: 1\n",
      "Tag: FS, Count: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Your existing code for tagging\n",
    "tokenizer = SinhalaTokenizer()\n",
    "# document = sentence  # Replace 'sentence' with your text\n",
    "tokenized_sentences = [tokenizer.tokenize(f'{ss}.') for ss in tokenizer.split_sentences(document)]\n",
    "tagger = POSTagger()\n",
    "pos_tags = tagger.predict(tokenized_sentences)\n",
    "\n",
    "# Count the occurrences of each unique tag\n",
    "tag_counts = defaultdict(int)\n",
    "tag_to_word = {}\n",
    "\n",
    "for sentence_tags in pos_tags:\n",
    "    for word, tag in sentence_tags:\n",
    "        tag_counts[tag] += 1\n",
    "        if tag not in tag_to_word:\n",
    "            tag_to_word[tag] = word\n",
    "\n",
    "# Print the tag counts\n",
    "for tag, count in tag_counts.items():\n",
    "    print(f\"Tag: {tag}, Count: {count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:20:48.858240200Z",
     "start_time": "2023-12-19T14:20:48.789227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original and Stemmed NNC Words:\n",
      "අමර -> ('අමර', '')\n",
      "දදයක් -> ('දද', 'යක්')\n",
      "ගෙදරට -> ('ගෙදර', 'ට')\n"
     ]
    }
   ],
   "source": [
    "from sinling import SinhalaTokenizer, POSTagger, SinhalaStemmer\n",
    "\n",
    "# Tokenize the document\n",
    "def tokenize_document(document):\n",
    "    tokenizer = SinhalaTokenizer()\n",
    "    tokenized_sentences = [tokenizer.tokenize(f'{ss}.') for ss in tokenizer.split_sentences(document)]\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "def pos_tagging(tokenized_sentences):\n",
    "    tagger = POSTagger()\n",
    "    pos_tags = tagger.predict(tokenized_sentences)\n",
    "    return pos_tags\n",
    "\n",
    "# Stem NNC words\n",
    "def stem_nnc_words(pos_tags):\n",
    "    stemmer = SinhalaStemmer()\n",
    "    stemmed_dict = {}\n",
    "\n",
    "    for sentence_tags in pos_tags:\n",
    "        for word, tag in sentence_tags:\n",
    "            # Check if the word has NNC (common noun) tag\n",
    "            if 'NNC' in tag:\n",
    "                # Stem the NNC word\n",
    "                stemmed_word = stemmer.stem(word)\n",
    "\n",
    "                # Save the original and stemmed word in the dictionary\n",
    "                stemmed_dict[word] = stemmed_word\n",
    "\n",
    "    return stemmed_dict\n",
    "\n",
    "# Example usage\n",
    "document = 'අමර ඔතන දදයක් තබන්න ඉන්පසු ඔබ ගෙදරට යන්න'\n",
    "\n",
    "# Tokenize the document\n",
    "tokenized_sentences = tokenize_document(document)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tagging(tokenized_sentences)\n",
    "\n",
    "# Stem NNC words and save in a dictionary\n",
    "stemmed_dict = stem_nnc_words(pos_tags)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original and Stemmed NNC Words:\")\n",
    "for word, stemmed_word in stemmed_dict.items():\n",
    "    print(f\"{word} -> {stemmed_word}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:21:18.950602500Z",
     "start_time": "2023-12-19T14:21:18.846456800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original and Stemmed NNC Words:\n",
      "අමර -> \n",
      "දද -> යක්\n",
      "ගෙදර -> ට\n"
     ]
    }
   ],
   "source": [
    "from sinling import SinhalaTokenizer, POSTagger, SinhalaStemmer\n",
    "\n",
    "# Tokenize the document\n",
    "def tokenize_document(document):\n",
    "    tokenizer = SinhalaTokenizer()\n",
    "    tokenized_sentences = [tokenizer.tokenize(f'{ss}.') for ss in tokenizer.split_sentences(document)]\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "def pos_tagging(tokenized_sentences):\n",
    "    tagger = POSTagger()\n",
    "    pos_tags = tagger.predict(tokenized_sentences)\n",
    "    return pos_tags\n",
    "\n",
    "# Stem NNC words\n",
    "def stem_nnc_words(pos_tags):\n",
    "    stemmer = SinhalaStemmer()\n",
    "    stemmed_dict = {}\n",
    "\n",
    "    for sentence_tags in pos_tags:\n",
    "        for word, tag in sentence_tags:\n",
    "            # Check if the word has NNC (common noun) tag\n",
    "            if 'NNC' in tag:\n",
    "                # Stem the NNC word\n",
    "                stemmed_word = stemmer.stem(word)\n",
    "\n",
    "                # Save the first part as the key and the second part as the value\n",
    "                stemmed_dict[stemmed_word[0]] = stemmed_word[1]\n",
    "\n",
    "    return stemmed_dict\n",
    "\n",
    "# Example usage\n",
    "document = 'අමර ඔතන දදයක් තබන්න ඉන්පසු ඔබ ගෙදරට යන්න'\n",
    "\n",
    "# Tokenize the document\n",
    "tokenized_sentences = tokenize_document(document)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = pos_tagging(tokenized_sentences)\n",
    "\n",
    "# Stem NNC words and save in a dictionary\n",
    "stemmed_dict = stem_nnc_words(pos_tags)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original and Stemmed NNC Words:\")\n",
    "for word, stemmed_word in stemmed_dict.items():\n",
    "    print(f\"{word} -> {stemmed_word}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:25:52.262532100Z",
     "start_time": "2023-12-19T14:25:52.105158600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching words and their counts:\n",
      "ගන්න: \t The Word Occurrence : 1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def search_csv(file_path, sentence):\n",
    "    with open(file_path,  mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)  # Assuming the first row is a header\n",
    "\n",
    "        # Assuming the sentence is in the first column (index 0)\n",
    "        sentence_column_index = 1\n",
    "\n",
    "        # Initialize a dictionary to store matching words and their counts\n",
    "        match_count_dict = {}\n",
    "\n",
    "        # Split the sentence into words\n",
    "        sentence_words = sentence.split()\n",
    "\n",
    "        for row in csv_reader:\n",
    "            # Get the word from the CSV column\n",
    "            csv_column_word = row[sentence_column_index]\n",
    "\n",
    "            # Check if the CSV column word is in the sentence\n",
    "            if csv_column_word in sentence_words:\n",
    "                # Update the match count in the dictionary\n",
    "                match_count_dict[csv_column_word] = match_count_dict.get(csv_column_word, 0) + 1\n",
    "\n",
    "        # Print the matching words and their counts\n",
    "        if match_count_dict:\n",
    "            print(\"Matching words and their counts:\")\n",
    "            for word, count in match_count_dict.items():\n",
    "                print(f\"{word}: \\t The Word Occurrence : {count}\")\n",
    "        else:\n",
    "            print(\"No matches found in the CSV file.\")\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'wsd_irst_attempt.csv'\n",
    "search_sentence = 'ඔතන තියෙන දදය ගන්න පසුව පැමිණෙනවා'\n",
    "\n",
    "search_csv(csv_file_path, search_sentence)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:27:17.596846600Z",
     "start_time": "2023-12-19T14:27:17.549969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching words and their counts:\n",
      "තබන්න: \t The Word Occurrence : 1\n",
      "Updated Sentence: අමර ඔතන කොඩිය තබන්න ඉන්පසු ඔබ ගෙදරට යන්න\n"
     ]
    }
   ],
   "source": [
    "# Example usage (In here i didnt use the Stemmer to segment the Words)\n",
    "def search_and_replace(file_path, sentence):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader)  # Assuming the first row is a header\n",
    "\n",
    "        # Assuming the sentence is in the first column (index 0)\n",
    "        sentence_column_index_1 = 0  # Noun column in the CSV file\n",
    "        sentence_column_index_2 = 1  # Verb column in the CSV file\n",
    "        replacement_column_index = 2  # Replacement Noun column in the CSV file\n",
    "\n",
    "        updated_sentence = sentence\n",
    "\n",
    "        # Split the sentence into words\n",
    "        sentence_words = sentence.split()\n",
    "\n",
    "        for row in csv_reader:\n",
    "            # Get the words from the CSV columns\n",
    "            csv_column_word_1 = row[sentence_column_index_1]\n",
    "            csv_column_word_2 = row[sentence_column_index_2]\n",
    "            replacement_word = row[replacement_column_index]\n",
    "\n",
    "            # Check if the words from both columns are in the sentence\n",
    "            if csv_column_word_1 in sentence_words and csv_column_word_2 in sentence_words:\n",
    "                # Replace the first word in the sentence with the replacement word\n",
    "                updated_sentence = updated_sentence.replace(csv_column_word_1, replacement_word)\n",
    "                break  # Assuming you want to replace only the first occurrence\n",
    "\n",
    "        print(\"Updated Sentence:\", updated_sentence)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'wsd_irst_attempt.csv'\n",
    "\n",
    "# Test Case 1\n",
    "search_sentence = 'අමර ඔතන දදය තබන්න ඉන්පසු ඔබ ගෙදරට යන්න'\n",
    "search_csv(csv_file_path, search_sentence)\n",
    "search_and_replace(csv_file_path, search_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:28:37.602057100Z",
     "start_time": "2023-12-19T14:28:37.571712500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching words and their counts:\n",
      "පැසවන්න: \t The Word Occurrence : 1\n",
      "Updated Sentence: නයන තුවාලය පැසවන්න හදනවා ඉක්මනට කිය සුව කරගන්න\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2\n",
    "search_sentence = 'නයන දදය පැසවන්න හදනවා ඉක්මනට කිය සුව කරගන්න'\n",
    "search_csv(csv_file_path, search_sentence)\n",
    "search_and_replace(csv_file_path, search_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T14:29:03.434083600Z",
     "start_time": "2023-12-19T14:29:03.387210100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
